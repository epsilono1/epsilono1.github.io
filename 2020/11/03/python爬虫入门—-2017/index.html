<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>python爬虫入门—_2017 | Epsilono1</title>
  <meta name="keywords" content=" python爬虫 , 爬虫入门 , 爬虫学习路线 ">
  <meta name="description" content="python爬虫入门—_2017 | Epsilono1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="博主介绍袁会洪，man，毕业于川大，好辣子鸡丁，喜晨跑。从事过机器人编程，弄过python网页爬虫，欲从事爬虫相关工作。专注力两极分化，认真办事时废寝忘食，放松时乐不思蜀，都需要闹钟提醒。 联系方式 QQ: 2213291696 Email: 2213291696@qq.com">
<meta property="og:type" content="website">
<meta property="og:title" content="about">
<meta property="og:url" content="http://epsilono1.github.io/about/index.html">
<meta property="og:site_name" content="Epsilono1">
<meta property="og:description" content="博主介绍袁会洪，man，毕业于川大，好辣子鸡丁，喜晨跑。从事过机器人编程，弄过python网页爬虫，欲从事爬虫相关工作。专注力两极分化，认真办事时废寝忘食，放松时乐不思蜀，都需要闹钟提醒。 联系方式 QQ: 2213291696 Email: 2213291696@qq.com">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-06-05T13:37:54.000Z">
<meta property="article:modified_time" content="2020-06-05T17:02:40.763Z">
<meta property="article:author" content="Epsilono1">
<meta name="twitter:card" content="summary">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.1.0" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.1.0" rel="stylesheet">

<link href="//cdn.jsdelivr.net/npm/animate.css@4.1.0/animate.min.css" rel="stylesheet">

<script src="//cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js"></script>
<script src="/js/titleTip.js?v=1.1.0" ></script>

<script src="//cdn.jsdelivr.net/npm/highlightjs@9.16.2/highlight.pack.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js"></script>



<script src="//cdn.jsdelivr.net/npm/jquery.cookie@1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.1.0" ></script>

<meta name="generator" content="Hexo 4.2.1"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="">
  <input class="theme_blog_path" value="">
  <input id="theme_shortcut" value="true" />
</div>


<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/" class="avatar_target">
    <img class="avatar" src="/img/avatar.jpg" />
</a>
<div class="author">
    <span>Epsilono1</span>
</div>

<div class="icon">
    
        
        <a title="rss" href="/atom.xml" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-rss"></use>
                </svg>
            
        </a>
        
    
        
        <a title="github" href="https://github.com/epsilono1" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-github"></use>
                </svg>
            
        </a>
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
        <a title="zhihu" href="https://www.zhihu.com/people/yan-hong-81-65" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-zhihu"></use>
                </svg>
            
        </a>
        
    
        
        <a title="csdn" href="https://blog.csdn.net/epsilono1" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-csdn"></use>
                </svg>
            
        </a>
        
    
        
    
        
    
        
        <a title="email" href="mailto:hong.yhh@qq.com" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-email"></use>
                </svg>
            
        </a>
        
    
        
        <a title="qq" href="http://wpa.qq.com/msgrd?v=3&uin=2213291696&site=qq&menu=yes" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-qq"></use>
                </svg>
            
        </a>
        
    
        
    
        
        <a title="neteasemusic" href="https://music.163.com/#/user/home?id=13887455" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-neteasemusic"></use>
                </svg>
            
        </a>
        
    
</div>




<ul>
    <li><div class="all active" data-rel="All">All<small>(9)</small></div></li>
    
        
            
            <li><div data-rel="工具">工具<small>(4)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="奇技">奇技<small>(2)</small></div>
                
            </li>
            
        
    
        
            
            <li><div data-rel="爬虫">爬虫<small>(2)</small></div>
                
            </li>
            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
    
    
    
    
    </div>
    <div><a class="about  hasFriend  site_url"  href="/about">About</a><a style="width: 50%"  class="friends">Friends</a></div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="9">
<input type="hidden" id="yelog_site_word_count" value="7.1k">
<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        Links
        <i class="iconfont icon-left"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="http://yelog.org/">叶落阁</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <div class="right-top">
        <div id="default-panel">
            <i class="iconfont icon-search" data-title="搜索 快捷键 i"></i>
            <div class="right-title">All</div>
            <i class="iconfont icon-file-tree" data-title="切换到大纲视图 快捷键 w"></i>
        </div>
        <div id="search-panel">
            <i class="iconfont icon-left" data-title="返回"></i>
            <input id="local-search-input" />
            <label class="border-line" for="input"></label>
            <i class="iconfont icon-case-sensitive" data-title="大小写敏感"></i>
            <i class="iconfont icon-tag" data-title="标签"></i>
        </div>
        <div id="outline-panel" style="display: none">
            <div class="right-title">大纲</div>
            <i class="iconfont icon-list" data-title="切换到文章列表"></i>
        </div>
    </div>

    <div class="tags-list">
    <input id="tag-search" />
    <div class="tag-wrapper">
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>chrome快捷键</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>cmd快捷键</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Example</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>hexo</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Markdown</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>notepad++快捷键</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>pipenv</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>pycharm快捷键</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>python爬虫</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>sublime快捷键</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>sumatraPDF快捷键</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>Typora</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>vimium快捷键</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>vscode快捷键</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>写文章工具</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>包管理工具</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>效率工具</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>爬虫入门</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>爬虫学习路线</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>租房</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>租房注意事项</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>租房选择</a>
            </li>
        
            <li class="article-tag-list-item">
                <i class="iconfont icon-tag"></i><a>虚拟环境</a>
            </li>
        
    </div>

</div>

    
    <nav id="title-list-nav">
        
        <a id="top" class="All "
           href="/2020/06/05/hello-world/"
           data-tag=""
           data-author="" >
            <span class="post-title" title="Hello World">Hello World</span>
            <span class="post-date" title="2020-06-05 17:48:02">2020/06/05</span>
        </a>
        
        <a  class="All 爬虫 "
           href="/2020/11/03/python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E2%80%94-2017/"
           data-tag="python爬虫,爬虫入门,爬虫学习路线"
           data-author="" >
            <span class="post-title" title="python爬虫入门—_2017">python爬虫入门—_2017</span>
            <span class="post-date" title="2020-11-03 12:54:33">2020/11/03</span>
        </a>
        
        <a  class="All 奇技 "
           href="/2020/11/03/%E7%A7%9F%E6%88%BF%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/"
           data-tag="租房,租房选择,租房注意事项"
           data-author="" >
            <span class="post-title" title="租房注意事项">租房注意事项</span>
            <span class="post-date" title="2020-11-03 11:55:39">2020/11/03</span>
        </a>
        
        <a  class="All 奇技 "
           href="/2020/11/02/%E5%BF%AB%E6%8D%B7%E9%94%AE/"
           data-tag="chrome快捷键,cmd快捷键,notepad++快捷键,sublime快捷键,pycharm快捷键,vscode快捷键,sumatraPDF快捷键,vimium快捷键"
           data-author="" >
            <span class="post-title" title="快捷键">快捷键</span>
            <span class="post-date" title="2020-11-02 20:16:35">2020/11/02</span>
        </a>
        
        <a  class="All 工具 "
           href="/2020/11/02/Typora%E4%BD%BF%E7%94%A8/"
           data-tag="Typora,写文章工具,Markdown,效率工具"
           data-author="" >
            <span class="post-title" title="Typora使用">Typora使用</span>
            <span class="post-date" title="2020-11-02 20:08:51">2020/11/02</span>
        </a>
        
        <a  class="All 爬虫 "
           href="/2020/11/02/pipenv%E4%BD%BF%E7%94%A8/"
           data-tag="pipenv,包管理工具,虚拟环境"
           data-author="" >
            <span class="post-title" title="pipenv使用（windows）">pipenv使用（windows）</span>
            <span class="post-date" title="2020-11-02 19:44:58">2020/11/02</span>
        </a>
        
        <a  class="All 工具 "
           href="/2020/06/06/Hexo-Github-Pages%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"
           data-tag="hexo"
           data-author="" >
            <span class="post-title" title="Hexo+Github Pages搭建个人博客">Hexo+Github Pages搭建个人博客</span>
            <span class="post-date" title="2020-06-06 20:51:29">2020/06/06</span>
        </a>
        
        <a  class="All 工具 "
           href="/2020/06/05/%E6%B5%8B%E8%AF%95%E7%B1%BB%E5%88%AB%E4%B8%8E%E6%A0%87%E7%AD%BE/"
           data-tag="Example"
           data-author="" >
            <span class="post-title" title="第一篇博客">第一篇博客</span>
            <span class="post-date" title="2020-06-05 23:03:29">2020/06/05</span>
        </a>
        
        <a  class="All 工具 "
           href="/2020/06/05/%E6%B5%8B%E8%AF%95%E4%BB%A3%E7%A0%81%E9%AB%98%E4%BA%AE%E5%8F%8A%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD/"
           data-tag="Example"
           data-author="" >
            <span class="post-title" title="第一篇文章">第一篇文章</span>
            <span class="post-date" title="2020-06-05 18:28:48">2020/06/05</span>
        </a>
        
        <div id="no-item-tips">

        </div>
    </nav>
    <div id="outline-list">
    </div>
</div>
    </div>
    <div class="hide-list">
        <div class="semicircle" data-title="切换全屏 快捷键 s">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div id="post">
    <div class="pjax">
        <article id="post-python爬虫入门—-2017" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">python爬虫入门—_2017</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            <i class="iconfont icon-category"></i>
            
            
            <a  data-rel="爬虫">爬虫</a>
            
        </span>
        
        
        <span class="tag">
            <i class="iconfont icon-tag"></i>
            
            <a class="color4">python爬虫</a>
            
            <a class="color5">爬虫入门</a>
            
            <a class="color2">爬虫学习路线</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
            Created At : <time class="date" title='Updated At: 2020-11-03 12:56:15'>2020-11-03 12:54</time>
        
    </div>
    <div class="article-meta">
        
        <span>Count:2.6k</span>
        
        
        <span id="busuanzi_container_page_pv">
            Views 👀 :<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
        <span class="top-comment" title="跳转至评论区">
            <a href="#comments">
                Comment:<span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </a>
        </span>
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Python入门网络爬虫之精华版"><span class="toc-text">Python入门网络爬虫之精华版</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#抓取"><span class="toc-text">抓取</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-最基本的抓取"><span class="toc-text">1. 最基本的抓取</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-对于登陆情况的处理"><span class="toc-text">2. 对于登陆情况的处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-对于反爬虫机制的处理"><span class="toc-text">3. 对于反爬虫机制的处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-对于断线重连"><span class="toc-text">4. 对于断线重连</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-多进程抓取"><span class="toc-text">5. 多进程抓取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-对于Ajax请求的处理"><span class="toc-text">6. 对于Ajax请求的处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-自动化测试工具Selenium"><span class="toc-text">7. 自动化测试工具Selenium</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-验证码识别"><span class="toc-text">8. 验证码识别</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分析"><span class="toc-text">分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#存储"><span class="toc-text">存储</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy"><span class="toc-text">Scrapy</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Robots协议"><span class="toc-text">Robots协议</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Robots协议规则"><span class="toc-text">1. Robots协议规则</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-Robots协议举例"><span class="toc-text">2. Robots协议举例</span></a></li></ol></li></ol></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Python入门网络爬虫之精华版"><a href="#Python入门网络爬虫之精华版" class="headerlink" title="Python入门网络爬虫之精华版"></a><a href="https://github.com/lining0806/PythonSpiderNotes" target="_blank" rel="noopener">Python入门网络爬虫之精华版</a></h1><hr>
<p><em>注：本文转自github：<a href="https://github.com/lining0806/PythonSpiderNotes" target="_blank" rel="noopener">Python入门网络爬虫之精华版</a></em></p>
<p><em>提醒：本文虽是2017年的，但思路值得借鉴</em></p>
<p>Python学习网络爬虫主要分3个大的版块：<strong>抓取</strong>，<strong>分析</strong>，<strong>存储</strong>  </p>
<p>另外，比较常用的爬虫框架<a href="http://scrapy.org/" target="_blank" rel="noopener">Scrapy</a>，这里最后也详细介绍一下。    </p>
<p>首先列举一下本人总结的相关文章，这些覆盖了入门网络爬虫需要的基本概念和技巧：<a href="http://www.lining0806.com/category/spider/" target="_blank" rel="noopener">宁哥的小站-网络爬虫</a>  </p>
<hr>
<p>当我们在浏览器中输入一个url后回车，后台会发生什么？比如说你输入<a href="http://www.lining0806.com/" target="_blank" rel="noopener">http://www.lining0806.com/</a>，你就会看到宁哥的小站首页。</p>
<p>简单来说这段过程发生了以下四个步骤：</p>
<ul>
<li>查找域名对应的IP地址。</li>
<li>向IP对应的服务器发送请求。</li>
<li>服务器响应请求，发回网页内容。</li>
<li>浏览器解析网页内容。</li>
</ul>
<p>网络爬虫要做的，简单来说，就是实现浏览器的功能。通过指定url，直接返回给用户所需要的数据，而不需要一步步人工去操纵浏览器获取。</p>
<h2 id="抓取"><a href="#抓取" class="headerlink" title="抓取"></a>抓取</h2><p>这一步，你要明确要得到的内容是什么？是HTML源码，还是Json格式的字符串等。  </p>
<h4 id="1-最基本的抓取"><a href="#1-最基本的抓取" class="headerlink" title="1. 最基本的抓取"></a>1. 最基本的抓取</h4><p>抓取大多数情况属于get请求，即直接从对方服务器上获取数据。  </p>
<p>首先，Python中自带urllib及urllib2这两个模块，基本上能满足一般的页面抓取。另外，<a href="https://github.com/kennethreitz/requests" target="_blank" rel="noopener">requests</a>也是非常有用的包，与此类似的，还有<a href="https://github.com/jcgregorio/httplib2" target="_blank" rel="noopener">httplib2</a>等等。    </p>
<pre><code>Requests：
    import requests
    response = requests.get(url)
    content = requests.get(url).content
    print &quot;response headers:&quot;, response.headers
    print &quot;content:&quot;, content
Urllib2：
    import urllib2
    response = urllib2.urlopen(url)
    content = urllib2.urlopen(url).read()
    print &quot;response headers:&quot;, response.headers
    print &quot;content:&quot;, content
Httplib2：
    import httplib2
    http = httplib2.Http()
    response_headers, content = http.request(url, &#39;GET&#39;)
    print &quot;response headers:&quot;, response_headers
    print &quot;content:&quot;, content</code></pre><p>此外，对于带有查询字段的url，get请求一般会将来请求的数据附在url之后，以?分割url和传输数据，多个参数用&amp;连接。  </p>
<pre><code>data = {&#39;data1&#39;:&#39;XXXXX&#39;, &#39;data2&#39;:&#39;XXXXX&#39;}
Requests：data为dict，json
    import requests
    response = requests.get(url=url, params=data)
Urllib2：data为string
    import urllib, urllib2    
    data = urllib.urlencode(data)
    full_url = url+&#39;?&#39;+data
    response = urllib2.urlopen(full_url)</code></pre><p>相关参考：<a href="http://www.lining0806.com/%E7%BD%91%E6%98%93%E6%96%B0%E9%97%BB%E6%8E%92%E8%A1%8C%E6%A6%9C%E6%8A%93%E5%8F%96%E5%9B%9E%E9%A1%BE/" target="_blank" rel="noopener">网易新闻排行榜抓取回顾</a></p>
<p>参考项目：<a href="https://github.com/lining0806/PythonSpiderNotes/blob/master/NewsSpider" target="_blank" rel="noopener">网络爬虫之最基本的爬虫：爬取网易新闻排行榜</a></p>
<h3 id="2-对于登陆情况的处理"><a href="#2-对于登陆情况的处理" class="headerlink" title="2. 对于登陆情况的处理"></a>2. 对于登陆情况的处理</h3><p><strong>2.1 使用表单登陆</strong>  </p>
<p>这种情况属于post请求，即先向服务器发送表单数据，服务器再将返回的cookie存入本地。  </p>
<pre><code>data = {&#39;data1&#39;:&#39;XXXXX&#39;, &#39;data2&#39;:&#39;XXXXX&#39;}
Requests：data为dict，json
    import requests
    response = requests.post(url=url, data=data)
Urllib2：data为string
    import urllib, urllib2    
    data = urllib.urlencode(data)
    req = urllib2.Request(url=url, data=data)
    response = urllib2.urlopen(req)</code></pre><p><strong>2.2 使用cookie登陆</strong>  </p>
<p>使用cookie登陆，服务器会认为你是一个已登陆的用户，所以就会返回给你一个已登陆的内容。因此，需要验证码的情况可以使用带验证码登陆的cookie解决。  </p>
<pre><code>import requests            
requests_session = requests.session() 
response = requests_session.post(url=url_login, data=data) </code></pre><p>若存在验证码，此时采用response = requests_session.post(url=url_login, data=data)是不行的，做法应该如下：  </p>
<pre><code>response_captcha = requests_session.get(url=url_login, cookies=cookies)
response1 = requests.get(url_login) # 未登陆
response2 = requests_session.get(url_login) # 已登陆，因为之前拿到了Response Cookie！
response3 = requests_session.get(url_results) # 已登陆，因为之前拿到了Response Cookie！</code></pre><p>相关参考：<a href="http://www.lining0806.com/6-%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB-%E9%AA%8C%E8%AF%81%E7%A0%81%E7%99%BB%E9%99%86/" target="_blank" rel="noopener">网络爬虫-验证码登陆</a>  </p>
<p>参考项目：<a href="https://github.com/lining0806/PythonSpiderNotes/blob/master/ZhihuSpider" target="_blank" rel="noopener">网络爬虫之用户名密码及验证码登陆：爬取知乎网站</a>  </p>
<h3 id="3-对于反爬虫机制的处理"><a href="#3-对于反爬虫机制的处理" class="headerlink" title="3. 对于反爬虫机制的处理"></a>3. 对于反爬虫机制的处理</h3><p><strong>3.1 使用代理</strong> </p>
<p>适用情况：限制IP地址情况，也可解决由于“频繁点击”而需要输入验证码登陆的情况。  </p>
<p>这种情况最好的办法就是维护一个代理IP池，网上有很多免费的代理IP，良莠不齐，可以通过筛选找到能用的。对于“频繁点击”的情况，我们还可以通过限制爬虫访问网站的频率来避免被网站禁掉。</p>
<pre><code>proxies = {&#39;http&#39;:&#39;http://XX.XX.XX.XX:XXXX&#39;}
Requests：
    import requests
    response = requests.get(url=url, proxies=proxies)
Urllib2：
    import urllib2
    proxy_support = urllib2.ProxyHandler(proxies)
    opener = urllib2.build_opener(proxy_support, urllib2.HTTPHandler)
    urllib2.install_opener(opener) # 安装opener，此后调用urlopen()时都会使用安装过的opener对象
    response = urllib2.urlopen(url)</code></pre><p><strong>3.2 时间设置</strong> </p>
<p>适用情况：限制频率情况。 </p>
<p>Requests，Urllib2都可以使用time库的sleep()函数：</p>
<pre><code>import time
time.sleep(1)</code></pre><p><strong>3.3 伪装成浏览器，或者反“反盗链”</strong>  </p>
<p>有些网站会检查你是不是真的浏览器访问，还是机器自动访问的。这种情况，加上User-Agent，表明你是浏览器访问即可。有时还会检查是否带Referer信息还会检查你的Referer是否合法，一般再加上Referer。</p>
<pre><code>headers = {&#39;User-Agent&#39;:&#39;XXXXX&#39;} # 伪装成浏览器访问，适用于拒绝爬虫的网站
headers = {&#39;Referer&#39;:&#39;XXXXX&#39;}
headers = {&#39;User-Agent&#39;:&#39;XXXXX&#39;, &#39;Referer&#39;:&#39;XXXXX&#39;}
Requests：
    response = requests.get(url=url, headers=headers)
Urllib2：
    import urllib, urllib2   
    req = urllib2.Request(url=url, headers=headers)
    response = urllib2.urlopen(req)</code></pre><h3 id="4-对于断线重连"><a href="#4-对于断线重连" class="headerlink" title="4. 对于断线重连"></a>4. 对于断线重连</h3><p>不多说。</p>
<pre><code>def multi_session(session, *arg):
    retryTimes = 20
    while retryTimes&gt;0:
        try:
            return session.post(*arg)
        except:
            print &#39;.&#39;,
            retryTimes -= 1</code></pre><p>或者  </p>
<pre><code>def multi_open(opener, *arg):
    retryTimes = 20
    while retryTimes&gt;0:
        try:
            return opener.open(*arg)
        except:
            print &#39;.&#39;,
            retryTimes -= 1</code></pre><p>这样我们就可以使用multi_session或multi_open对爬虫抓取的session或opener进行保持。    </p>
<h3 id="5-多进程抓取"><a href="#5-多进程抓取" class="headerlink" title="5. 多进程抓取"></a>5. 多进程抓取</h3><p>这里针对<a href="http://live.wallstreetcn.com/" target="_blank" rel="noopener">华尔街见闻</a>进行并行抓取的实验对比：<a href="https://github.com/lining0806/PythonSpiderNotes/blob/master/Spider_Python" target="_blank" rel="noopener">Python多进程抓取</a> 与 <a href="https://github.com/lining0806/PythonSpiderNotes/blob/master/Spider_Java" target="_blank" rel="noopener">Java单线程和多线程抓取</a>  </p>
<p>相关参考：<a href="http://www.lining0806.com/%E5%85%B3%E4%BA%8Epython%E5%92%8Cjava%E7%9A%84%E5%A4%9A%E8%BF%9B%E7%A8%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94/" target="_blank" rel="noopener">关于Python和Java的多进程多线程计算方法对比</a>  </p>
<h3 id="6-对于Ajax请求的处理"><a href="#6-对于Ajax请求的处理" class="headerlink" title="6. 对于Ajax请求的处理"></a>6. 对于Ajax请求的处理</h3><p>对于“加载更多”情况，使用Ajax来传输很多数据。</p>
<p>它的工作原理是：从网页的url加载网页的源代码之后，会在浏览器里执行JavaScript程序。这些程序会加载更多的内容，“填充”到网页里。这就是为什么如果你直接去爬网页本身的url，你会找不到页面的实际内容。  </p>
<p>这里，若使用Google Chrome分析”请求“对应的链接(方法：右键→审查元素→Network→清空，点击”加载更多“，出现对应的GET链接寻找Type为text/html的，点击，查看get参数或者复制Request URL)，循环过程。  </p>
<ul>
<li>如果“请求”之前有页面，依据上一步的网址进行分析推导第1页。以此类推，抓取抓Ajax地址的数据。  </li>
<li>对返回的json格式数据(str)进行正则匹配。json格式数据中，需从’\uxxxx’形式的unicode_escape编码转换成u’\uxxxx’的unicode编码。  </li>
</ul>
<h3 id="7-自动化测试工具Selenium"><a href="#7-自动化测试工具Selenium" class="headerlink" title="7. 自动化测试工具Selenium"></a>7. 自动化测试工具Selenium</h3><p>Selenium是一款自动化测试工具。它能实现操纵浏览器，包括字符填充、鼠标点击、获取元素、页面切换等一系列操作。总之，凡是浏览器能做的事，Selenium都能够做到。</p>
<p>这里列出在给定城市列表后，使用selenium来动态抓取<a href="http://flight.qunar.com/" target="_blank" rel="noopener">去哪儿网</a>的票价信息的代码。</p>
<p>参考项目：<a href="https://github.com/lining0806/PythonSpiderNotes/blob/master/QunarSpider" target="_blank" rel="noopener">网络爬虫之Selenium使用代理登陆：爬取去哪儿网站</a> </p>
<h3 id="8-验证码识别"><a href="#8-验证码识别" class="headerlink" title="8. 验证码识别"></a>8. 验证码识别</h3><p>对于网站有验证码的情况，我们有三种办法：  </p>
<ul>
<li>使用代理，更新IP。</li>
<li>使用cookie登陆。</li>
<li>验证码识别。</li>
</ul>
<p>使用代理和使用cookie登陆之前已经讲过，下面讲一下验证码识别。  </p>
<p>可以利用开源的Tesseract-OCR系统进行验证码图片的下载及识别，将识别的字符传到爬虫系统进行模拟登陆。当然也可以将验证码图片上传到打码平台上进行识别。如果不成功，可以再次更新验证码识别，直到成功为止。  </p>
<p>参考项目：<a href="https://github.com/lining0806/PythonSpiderNotes/blob/master/Captcha1" target="_blank" rel="noopener">验证码识别项目第一版：Captcha1</a></p>
<p><strong>爬取有两个需要注意的问题：</strong></p>
<ul>
<li>如何监控一系列网站的更新情况，也就是说，如何进行增量式爬取？</li>
<li>对于海量数据，如何实现分布式爬取？</li>
</ul>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>抓取之后就是对抓取的内容进行分析，你需要什么内容，就从中提炼出相关的内容来。  </p>
<p>常见的分析工具有<a href="http://deerchao.net/tutorials/regex/regex.htm" target="_blank" rel="noopener">正则表达式</a>，<a href="http://www.crummy.com/software/BeautifulSoup/" target="_blank" rel="noopener">BeautifulSoup</a>，<a href="http://lxml.de/" target="_blank" rel="noopener">lxml</a>等等。  </p>
<h2 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h2><p>分析出我们需要的内容之后，接下来就是存储了。  </p>
<p>我们可以选择存入文本文件，也可以选择存入<a href="http://www.mysql.com/" target="_blank" rel="noopener">MySQL</a>或<a href="https://www.mongodb.org/" target="_blank" rel="noopener">MongoDB</a>数据库等。  </p>
<p><strong>存储有两个需要注意的问题：</strong></p>
<ul>
<li>如何进行网页去重？</li>
<li>内容以什么形式存储？</li>
</ul>
<h2 id="Scrapy"><a href="#Scrapy" class="headerlink" title="Scrapy"></a>Scrapy</h2><p>Scrapy是一个基于Twisted的开源的Python爬虫框架，在工业中应用非常广泛。  </p>
<p>相关内容可以参考<a href="http://www.lining0806.com/%E5%9F%BA%E4%BA%8Escrapy%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E7%9A%84%E6%90%AD%E5%BB%BA/" target="_blank" rel="noopener">基于Scrapy网络爬虫的搭建</a>，同时给出这篇文章介绍的<a href="http://weixin.sogou.com/weixin" target="_blank" rel="noopener">微信搜索</a>爬取的项目代码，给大家作为学习参考。</p>
<p>参考项目：<a href="https://github.com/lining0806/PythonSpiderNotes/blob/master/WechatSearchProjects" target="_blank" rel="noopener">使用Scrapy或Requests递归抓取微信搜索结果</a></p>
<h2 id="Robots协议"><a href="#Robots协议" class="headerlink" title="Robots协议"></a>Robots协议</h2><p>好的网络爬虫，首先需要遵守<strong>Robots协议</strong>。Robots协议（也称为爬虫协议、机器人协议等）的全称是“网络爬虫排除标准”（Robots Exclusion Protocol），网站通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。</p>
<p>在网站根目录下放一个robots.txt文本文件（如 <a href="https://www.taobao.com/robots.txt" target="_blank" rel="noopener">https://www.taobao.com/robots.txt</a> ），里面可以指定不同的网络爬虫能访问的页面和禁止访问的页面，指定的页面由正则表达式表示。网络爬虫在采集这个网站之前，首先获取到这个robots.txt文本文件，然后解析到其中的规则，然后根据规则来采集网站的数据。</p>
<h3 id="1-Robots协议规则"><a href="#1-Robots协议规则" class="headerlink" title="1. Robots协议规则"></a>1. Robots协议规则</h3><pre><code>User-agent: 指定对哪些爬虫生效
Disallow: 指定不允许访问的网址
Allow: 指定允许访问的网址</code></pre><p>注意: 一个英文要大写，冒号是英文状态下，冒号后面有一个空格，”/“代表整个网站</p>
<h3 id="2-Robots协议举例"><a href="#2-Robots协议举例" class="headerlink" title="2. Robots协议举例"></a>2. Robots协议举例</h3><pre><code>禁止所有机器人访问
    User-agent: *
    Disallow: /
允许所有机器人访问
    User-agent: *
    Disallow: 
禁止特定机器人访问
    User-agent: BadBot
    Disallow: /
允许特定机器人访问
    User-agent: GoodBot
    Disallow: 
禁止访问特定目录
    User-agent: *
    Disallow: /images/
仅允许访问特定目录
    User-agent: *
    Allow: /images/
    Disallow: /
禁止访问特定文件
    User-agent: *
    Disallow: /*.html$
仅允许访问特定文件
    User-agent: *
    Allow: /*.html$
    Disallow: /</code></pre>
      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。可以在下面评论区评论，也可以邮件至 2213291696@qq.com </span>
    </div>
</article>


<p>
    <a  class="dashang" onclick="dashangToggle()">💰</a>
</p>




    <div id="comments"></div>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

<script type="text/javascript">
    $.getScript('/js/gitalk.js', function () {
        var gitalk = new Gitalk({
            clientID: '9590840e2e1fb09145a5',
            clientSecret: '8f51c91c33e186cc7d057a1da7ef79667bb96578',
            repo: 'epsilono1.github.io',
            owner: 'epsilono1',
            admin: ['epsilono1'],
            id: decodeURI(location.pathname),
            distractionFreeMode: 'true',
            language: 'zh-CN',
            perPage: parseInt('10',10)
        })
        gitalk.render('comments')
    })
</script>




    




    </div>
    <div class="copyright">
        <p class="footer-entry">
    ©2020 epsilono1
</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full" data-title="切换全屏 快捷键 s"><span class="min "></span></button>
<a class="" id="rocket" ></a>

    </div>
</div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close"  onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>Help us with donation</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">alipay</label></span><span><label><input type="radio" name="pay" value="weixin">weixin</label></span>
    </div>
</div>


</body>
<script src="/js/jquery.pjax.js?v=1.1.0" ></script>

<script src="/js/script.js?v=1.1.0" ></script>
<script>
    var img_resize = 'default';
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $("#post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    

    
</style>







<div style="position:absolute; bottom: 0; right: 0;">
    <embed src="//music.163.com/style/swf/widget.swf?sid=437753234&type=2&auto=1&width=278&height=32" width="298" height="52"  allowNetworking="all"></embed>
</div>
</html>
